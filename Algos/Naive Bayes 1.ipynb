{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa8df6b-862d-4d32-9f44-bb5e8dc098df",
   "metadata": {},
   "source": [
    "# Naive Bayes 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813a4a7-860e-480d-a631-f42f6747f2cf",
   "metadata": {},
   "source": [
    "**Q1. What is Bayes' theorem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6ca2d-e058-48fc-ab89-d8c5271fd366",
   "metadata": {},
   "source": [
    "**Ans:**  \n",
    "\n",
    "**Bayes' Theorem**\n",
    "\n",
    "Bayes' theorem is a fundamental concept in probability theory and statistics that describes how to update the probability of a hypothesis based on new evidence. It's named after the 18th-century statistician Thomas Bayes.\n",
    "\n",
    "In simple terms, Bayes' theorem provides a way to calculate the likelihood of a given event based on prior knowledge and new data. The theorem is expressed mathematically as:\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Here's what each term represents:\n",
    "\n",
    "- **$P(A \\mid B)$** is the **posterior probability**: the probability of event $A$ occurring given that $B$ has occurred.\n",
    "- **$P(B \\mid A)$** is the **likelihood**: the probability of observing $B$ given that $A$ is true.\n",
    "- **$P(A)$** is the **prior probability**: the initial probability of $A$ before taking into account the new evidence $B$.\n",
    "- **$P(B)$** is the **marginal probability**: the total probability of observing $B$ under all possible scenarios.\n",
    "\n",
    "Bayes' theorem is widely used in various fields, including statistics, machine learning, and even everyday decision-making. It helps in updating beliefs or hypotheses when new data becomes available, which makes it a powerful tool for reasoning under uncertainty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f396b5c-4974-4652-b5ff-debd2572b591",
   "metadata": {},
   "source": [
    "**Q2. What is the formula for Bayes' theorem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8dcab-3f8a-4d24-bb51-1d590faa225a",
   "metadata": {},
   "source": [
    "**Ans:**  \n",
    "\n",
    "The theorem is expressed mathematically as:\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Here's what each term represents:\n",
    "\n",
    "- **$P(A \\mid B)$** is the **posterior probability**: the probability of event $A$ occurring given that $B$ has occurred.\n",
    "- **$P(B \\mid A)$** is the **likelihood**: the probability of observing $B$ given that $A$ is true.\n",
    "- **$P(A)$** is the **prior probability**: the initial probability of $A$ before taking into account the new evidence $B$.\n",
    "- **$P(B)$** is the **marginal probability**: the total probability of observing $B$ under all possible scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37e49a-7d96-4a59-9304-268d8e7c5214",
   "metadata": {},
   "source": [
    "**Q3. How is Bayes' theorem used in practice?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d8867-389d-47b7-8730-cba74ea437c2",
   "metadata": {},
   "source": [
    "**Ans:**  \n",
    "  \n",
    "Bayes' theorem is applied in numerous practical scenarios across various fields. Here are some key examples:\n",
    "\n",
    "**1. Medical Diagnosis**\n",
    "\n",
    "Bayes' theorem helps doctors assess the probability of a disease given the results of diagnostic tests. For instance, if a test has a known sensitivity (true positive rate) and specificity (true negative rate), Bayes' theorem can be used to update the probability of having the disease based on the test result and the prevalence of the disease in the population.\n",
    "\n",
    "*Example*: If a test for a rare disease is positive, Bayes' theorem can be used to determine how likely it is that the patient actually has the disease, considering both the test accuracy and the base rate of the disease.\n",
    "\n",
    "**2. Spam Filtering**\n",
    "\n",
    "Bayesian spam filters use Bayes' theorem to classify emails as spam or not spam based on the frequency of certain words in emails. The filter updates its probability estimates based on the occurrence of specific words or patterns associated with spam.\n",
    "\n",
    "*Example*: If certain words like \"free\" or \"win\" are more common in spam emails, a Bayesian filter calculates the probability that an email is spam given the presence of these words.\n",
    "\n",
    "**3. Risk Assessment**\n",
    "\n",
    "In finance and insurance, Bayes' theorem helps assess risks and make decisions based on historical data and new information. For instance, it can be used to evaluate the risk of a financial asset or the likelihood of a claim being fraudulent.\n",
    "\n",
    "*Example*: An insurance company might use Bayes' theorem to update the probability of a customer filing a claim based on new information about the customer’s behavior or changes in their risk profile.\n",
    "\n",
    "**4. Machine Learning and AI**\n",
    "\n",
    "Bayesian methods are used in machine learning for probabilistic modeling and inference. Bayesian networks, for instance, are graphical models that represent the probabilistic relationships among a set of variables.\n",
    "\n",
    "*Example*: In a recommendation system, Bayesian methods can update the probability of a user liking a particular item based on their past preferences and the preferences of similar users.\n",
    "\n",
    "**5. Decision Making**\n",
    "\n",
    "Bayes' theorem helps in decision-making processes by updating probabilities as new information becomes available, thereby refining decisions based on the most current data.\n",
    "\n",
    "*Example*: A company might use Bayes' theorem to adjust its market strategy based on changing consumer preferences and new market research.\n",
    "\n",
    "**6. Genetics and Epidemiology**\n",
    "\n",
    "In genetics, Bayes' theorem is used to calculate the probability of inheriting a genetic trait or disease. In epidemiology, it helps estimate the likelihood of an outbreak given observed cases and other relevant data.\n",
    "\n",
    "*Example*: In studying genetic disorders, Bayes' theorem helps estimate the probability of a child having a genetic condition based on parental genotypes and family history.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727027f8-dc0e-45f0-bda9-4a02ca59281a",
   "metadata": {},
   "source": [
    "**Q4. What is the relationship between Bayes' theorem and conditional probability?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f00e896-1da7-43d3-9bce-f5877678329e",
   "metadata": {},
   "source": [
    "**Ans:**  \n",
    "\n",
    "**Conditional Probability** is a measure of the probability of an event occurring given that another event has already occurred. It is denoted as $P(A|B)$, which reads as \"the probability of event A given event B.\" The formula for conditional probability is:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $P(A \\cap B)$ is the probability that both events A and B occur.\n",
    "- $P(B)$ is the probability that event B occurs.\n",
    "\n",
    "**Bayes' Theorem** provides a way to update the probability of an event based on new information. It relates the conditional probability of event A given event B to the conditional probability of event B given event A. The formula for Bayes' theorem is:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $P(A|B)$ is the posterior probability, the probability of event A given that event B has occurred.\n",
    "- $P(B|A)$ is the likelihood, the probability of event B given that event A has occurred.\n",
    "- $P(A)$ is the prior probability, the initial probability of event A.\n",
    "- $P(B)$ is the marginal probability of event B.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1957d06-2a21-4bc8-9552-c7276707901b",
   "metadata": {},
   "source": [
    "**Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b91b85-e666-489b-b9ae-b91a0fb1ec76",
   "metadata": {},
   "source": [
    "**Ans:**  \n",
    "  \n",
    "Choosing the right type of Naive Bayes classifier depends on the nature of your data and the assumptions you can make about the distribution of features. Here’s a guide to help you select the appropriate Naive Bayes classifier for your problem:\n",
    "\n",
    "#### Types of Naive Bayes Classifiers\n",
    "\n",
    "1. **Multinomial Naive Bayes**\n",
    "   - **Use Case**: Best suited for text classification problems where the features represent counts or frequencies (e.g., word counts in documents).\n",
    "   - **Assumptions**: Assumes that features (words, in the case of text) follow a multinomial distribution. This is appropriate for cases where you have discrete features and each feature is an integer count.\n",
    "   - **Example**: Spam detection in emails, document classification.\n",
    "   \n",
    "   **Formula**:\n",
    "   $$\n",
    "   P(c|x) = \\frac{P(c) \\prod_{i=1}^n P(x_i|c)}{P(x)}\n",
    "   $$\n",
    "   where $P(x_i|c)$ is typically estimated from the frequency of feature $x_i$ in class $c$.\n",
    "\n",
    "2. **Bernoulli Naive Bayes**\n",
    "   - **Use Case**: Suitable for binary/boolean features where each feature is either present or absent (e.g., presence or absence of words in text).\n",
    "   - **Assumptions**: Assumes binary features and a Bernoulli distribution for each feature.\n",
    "   - **Example**: Document classification where the presence of certain words is important, not their frequency.\n",
    "\n",
    "   **Formula**:\n",
    "   $$\n",
    "   P(c|x) = \\frac{P(c) \\prod_{i=1}^n P(x_i|c)}{P(x)}\n",
    "   $$\n",
    "   where $P(x_i|c)$ is the probability of feature $x_i$ being present given class $c$.\n",
    "\n",
    "3. **Gaussian Naive Bayes**\n",
    "   - **Use Case**: Ideal for problems where features are continuous and can be assumed to follow a Gaussian (normal) distribution.\n",
    "   - **Assumptions**: Assumes that features follow a Gaussian distribution with class-specific mean and variance.\n",
    "   - **Example**: Classification problems where features are continuous variables, such as predicting customer behavior based on numerical data.\n",
    "\n",
    "   **Formula**:\n",
    "   $$\n",
    "   P(x_i|c) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left( -\\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right)\n",
    "   $$\n",
    "   where $\\mu$ and $\\sigma^2$ are the mean and variance of the feature $x_i$ in class $c$.\n",
    "\n",
    "#### Choosing the Right Classifier\n",
    "\n",
    "1. **Data Type and Feature Distribution**:\n",
    "   - **Discrete, Count-based Features**: Use **Multinomial Naive Bayes**.\n",
    "   - **Binary/Boolean Features**: Use **Bernoulli Naive Bayes**.\n",
    "   - **Continuous Features**: Use **Gaussian Naive Bayes**.\n",
    "\n",
    "2. **Feature Characteristics**:\n",
    "   - If your data consists of counts or frequencies and you want to leverage feature counts, Multinomial Naive Bayes is appropriate.\n",
    "   - If the features are binary (0 or 1) indicating presence or absence of a feature, Bernoulli Naive Bayes is more suitable.\n",
    "   - If the features are continuous and you can reasonably assume a normal distribution, Gaussian Naive Bayes is a good choice.\n",
    "\n",
    "3. **Performance and Evaluation**:\n",
    "   - It’s often useful to try multiple types of Naive Bayes classifiers and evaluate their performance using cross-validation or a hold-out validation set. This empirical approach can help you determine which classifier works best for your specific dataset and problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4a35e-58d9-45cd-8ce9-67690e01313a",
   "metadata": {},
   "source": [
    "**Q6. Assignment:**\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive  \n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of  \n",
    "each feature value for each class:  \n",
    "Class: X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4  \n",
    "     A   3   3    4    4    3    3    3  \n",
    "     B   2   2    1    2    2    2    3  \n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0430051c-c16b-40df-bd29-e8d65ec13342",
   "metadata": {},
   "source": [
    "**Ans:**  \n",
    "  \n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features \\( X1 = 3 \\) and \\( X2 = 4 \\). The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "| Class | X1=1 | X1=2 | X1=3 | X2=1 | X2=2 | X2=3 | X2=4 |\n",
    "|-------|------|------|------|------|------|------|------|\n",
    "| A     | 3    | 3    | 4    | 4    | 3    | 3    | 3    |\n",
    "| B     | 2    | 2    | 1    | 2    | 2    | 2    | 3    |\n",
    "\n",
    "Assuming equal prior probabilities for each class, we want to predict which class the new instance belongs to.\n",
    "\n",
    "#### 1. Prior Probabilities\n",
    "\n",
    "Since the prior probabilities are equal for each class, we have:\n",
    "\n",
    "$$\n",
    "P(A) = P(B) = \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "#### 2. Likelihoods\n",
    "\n",
    "We need to calculate the likelihood of observing \\( X1 = 3 \\) and \\( X2 = 4 \\) for each class.\n",
    "\n",
    "#### For Class A:\n",
    "- **Likelihood of \\( X1 = 3 \\) given A:**\n",
    "  \n",
    "  From the table, there are 4 instances of \\( X1 = 3 \\) out of \\( 3 + 3 + 4 = 10 \\) instances total for Class A.\n",
    "  \n",
    "  $$\n",
    "  P(X1 = 3 | A) = \\frac{4}{10} = 0.4\n",
    "  $$\n",
    "\n",
    "- **Likelihood of \\( X2 = 4 \\) given A:**\n",
    "\n",
    "  From the table, there are 3 instances of \\( X2 = 4 \\) out of \\( 4 + 3 + 3 + 3 = 13 \\) instances total for Class A.\n",
    "  \n",
    "  $$\n",
    "  P(X2 = 4 | A) = \\frac{3}{13} \\approx 0.231\n",
    "  $$\n",
    "\n",
    "#### For Class B:\n",
    "- **Likelihood of \\( X1 = 3 \\) given B:**\n",
    "  \n",
    "  From the table, there is 1 instance of \\( X1 = 3 \\) out of \\( 2 + 2 + 1 = 5 \\) instances total for Class B.\n",
    "  \n",
    "  $$\n",
    "  P(X1 = 3 | B) = \\frac{1}{5} = 0.2\n",
    "  $$\n",
    "\n",
    "- **Likelihood of \\( X2 = 4 \\) given B:**\n",
    "\n",
    "  From the table, there are 3 instances of \\( X2 = 4 \\) out of \\( 2 + 2 + 2 + 3 = 9 \\) instances total for Class B.\n",
    "  \n",
    "  $$\n",
    "  P(X2 = 4 | B) = \\frac{3}{9} = \\frac{1}{3} \\approx 0.333\n",
    "  $$\n",
    "\n",
    "#### 3. Posterior Probabilities\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "$$\n",
    "P(A | X1 = 3, X2 = 4) \\propto P(X1 = 3 | A) \\cdot P(X2 = 4 | A) \\cdot P(A)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(B | X1 = 3, X2 = 4) \\propto P(X1 = 3 | B) \\cdot P(X2 = 4 | B) \\cdot P(B)\n",
    "$$\n",
    "\n",
    "#### For Class A:\n",
    "\n",
    "$$\n",
    "P(A | X1 = 3, X2 = 4) \\propto 0.4 \\cdot 0.231 \\cdot 0.5 = 0.046\n",
    "$$\n",
    "\n",
    "#### For Class B:\n",
    "\n",
    "$$\n",
    "P(B | X1 = 3, X2 = 4) \\propto 0.2 \\cdot 0.333 \\cdot 0.5 = 0.033\n",
    "$$\n",
    "\n",
    "#### 4. Classification\n",
    "\n",
    "The posterior probability for Class A is approximately 0.046, and for Class B it is approximately 0.033. Since the posterior probability for Class A is higher than for Class B, the Naive Bayes classifier would predict that the new instance belongs to **Class A**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a995d123-bb31-42de-8c07-5655d4cda45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
