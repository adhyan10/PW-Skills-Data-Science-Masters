{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a37984-fa77-43ca-be95-0378503767b5",
   "metadata": {},
   "source": [
    "## Feature Engineering 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff255797-92fb-439a-b67f-acf4ae1fd860",
   "metadata": {},
   "source": [
    "1. What are missing values in a dataset? Why is it essential to handle missing values? Name some \n",
    "algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ae405-b538-482c-be3a-9a2a1ded3803",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "Missing values in a dataset refer to the absence of data for one or more variables for some records. This can happen for various reasons, such as data collection errors, non-responses in surveys, or issues in data entry.  \n",
    "  \n",
    "Why is it Essential to Handle Missing Values?  \n",
    "1. Accuracy: Missing values can lead to biased or incorrect results in statistical analysis and machine learning models. If not handled properly, they can skew the interpretation of data and model performance.  \n",
    "  \n",
    "2. Completeness: Many algorithms require a complete dataset to function correctly. Missing data can prevent the application of these algorithms or reduce the quality of their predictions.\n",
    "  \n",
    "3. Bias: Ignoring missing values or not addressing them appropriately can introduce bias into the model. For example, if missing data is not random and is related to certain patterns in the dataset, it can lead to inaccurate inferences.\n",
    "  \n",
    "4. Efficiency: Handling missing values helps in improving the efficiency and effectiveness of data analysis and model training, leading to more reliable and robust results.\n",
    "  \n",
    "Algorithms Not Affected by Missing Values\n",
    "1. Decision Trees: Can handle missing values by splitting nodes based on available data, and some implementations allow for surrogate splits.\n",
    "  \n",
    "2. Random Forests: Like decision trees, random forests can deal with missing values using various strategies, including surrogate splits or treating missing values as a separate category.\n",
    "  \n",
    "3. k-Nearest Neighbors (k-NN): When using k-NN, the distance metric can be adjusted to handle missing values. For example, only considering dimensions where both the query point and neighbors have values.\n",
    "  \n",
    "4. Naive Bayes: Often handles missing values by assuming that missing values do not influence the class probabilities directly, or by treating missing values as a separate category in some implementations.\n",
    "  \n",
    "5. Some implementations of Neural Networks: Advanced neural network architectures and implementations might handle missing data through mechanisms like dropout or embedding layers.\n",
    "  \n",
    "6. Robust Regression Models: Certain regression techniques are designed to handle missing values or make robust predictions despite incomplete data.\n",
    "  \n",
    "Choosing the right method to handle missing values depends on the nature of the dataset and the specific requirements of the analysis or modeling task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f5c5c-4d23-41c6-a56f-deef2ba0e025",
   "metadata": {},
   "source": [
    "#### 2. List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff1c99-bb19-49cb-b3e7-df8dad2f5f85",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "Handling missing data is a critical aspect of data preprocessing in data science and machine learning. There are several techniques used to handle missing data, each with its own advantages and use cases.\n",
    "some common techniques used for handling missing data are as follows:\n",
    "1. Dropping rows with missing values.\n",
    "2. Dropping columns that have many missing values\n",
    "3. Data imputation:  \n",
    "   a. mean  \n",
    "   b. median (if there are many outliers)  \n",
    "   c. mode (for categorical features)  \n",
    "4. Using machine learning aglorithms to impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e891a719-9a35-492b-9e8f-a4a88340cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0beaeb-8f9c-47e5-878d-c22c200e9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fde542-7d9f-486d-9ab7-1191af2235c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9ccb05-4488-4d84-8257-fed17b4b5f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a68b1a-a0dd-4f2c-a65f-fe8a1eecd508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29a11daf-d248-4e9b-8057-7d658d6edc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Droppig rows which contain missing values\n",
    "\n",
    "df_drop_row = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff425183-3882-461a-b7e7-a19a90c0b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 15)\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_drop_row.shape)\n",
    "print(df_drop_row.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7601ad90-7c17-42dc-ab53-0da1a3cc481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping cloumn that contains missing values\n",
    "\n",
    "df_drop_col = df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb975191-564f-4560-9e3a-6305fce59e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n",
      "survived      0\n",
      "pclass        0\n",
      "sex           0\n",
      "sibsp         0\n",
      "parch         0\n",
      "fare          0\n",
      "class         0\n",
      "who           0\n",
      "adult_male    0\n",
      "alive         0\n",
      "alone         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_drop_col.shape)\n",
    "print(df_drop_col.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d5cbdc3-a4ba-4723-9677-2f29e118d73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## imputation \n",
    "##mean\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e903c3e9-f9c5-4f3d-8a95-0738c1cdbeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imputing mean for the missing values in age column\n",
    "df[\"age_mean\"] = df[\"age\"].fillna(df[\"age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3de75318-b20e-402b-8fd1-54a4d50695b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imputing median for the missing values in the age column\n",
    "df[\"age_median\"] = df[\"age\"].fillna(df[\"age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c71e1cc4-8b1d-46a1-bdfd-55e23dff5e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_mean</th>\n",
       "      <th>age_median</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_mean  age_median   age\n",
       "0    22.000000        22.0  22.0\n",
       "1    38.000000        38.0  38.0\n",
       "2    26.000000        26.0  26.0\n",
       "3    35.000000        35.0  35.0\n",
       "4    35.000000        35.0  35.0\n",
       "..         ...         ...   ...\n",
       "886  27.000000        27.0  27.0\n",
       "887  19.000000        19.0  19.0\n",
       "888  29.699118        28.0   NaN\n",
       "889  26.000000        26.0  26.0\n",
       "890  32.000000        32.0  32.0\n",
       "\n",
       "[891 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"age_mean\",\"age_median\",\"age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97d7fd40-5a3f-4c3d-9ac1-d61343e67099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "      <th>age_mean</th>\n",
       "      <th>age_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch  fare embarked  class  \\\n",
       "61          1       1  female  38.0      0      0  80.0      NaN  First   \n",
       "829         1       1  female  62.0      0      0  80.0      NaN  First   \n",
       "\n",
       "       who  adult_male deck embark_town alive  alone  age_mean  age_median  \n",
       "61   woman       False    B         NaN   yes   True      38.0        38.0  \n",
       "829  woman       False    B         NaN   yes   True      62.0        62.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"embarked\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "063dd109-8b4f-4d63-86a0-5ac700b848e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embarked\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b9f5621-7452-494d-bb90-bedc704f49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mode = df[df[\"embarked\"].notna()][\"embarked\"].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7389ffb9-f0e8-4c9e-b815-cb7333b7323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embarked_mode\"] = df[\"embarked\"].fillna(embarked_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e588240-8021-4772-b855-f443d62f9d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked</th>\n",
       "      <th>embarked_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    embarked embarked_mode\n",
       "61       NaN             S\n",
       "829      NaN             S"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"embarked\"].isnull()][[\"embarked\",\"embarked_mode\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e48e7f9-dff7-4d5d-b9e9-31422b9ae226",
   "metadata": {},
   "source": [
    "#### 3.Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c742a8-3372-4b36-99ab-80bed302109b",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "Imbalanced Data refers to a situation in a classification problem where the classes are not represented equally in the dataset. This means that one class (often the target or outcome class) is significantly more frequent than the other(s). For example, in a medical dataset for detecting a rare disease, there might be many more instances of \"healthy\" patients compared to \"diseased\" patients.  \n",
    "  \n",
    "Consequences of Not Handling Imbalanced Data  \n",
    "If imbalanced data is not handled appropriately, it can lead to several problems:  \n",
    "  \n",
    "1. Poor Model Performance: Traditional classifiers may perform poorly on the minority class because they tend to be biased towards the majority class. For example, in a binary classification problem with a 95% majority class and a 5% minority class, a model that always predicts the majority class would achieve 95% accuracy. However, this model would fail to identify any instances of the minority class, which could be crucial.  \n",
    "\n",
    "2. Misleading Accuracy Metrics: Accuracy can be a misleading metric in the case of imbalanced datasets. High accuracy may be achieved by simply predicting the majority class most of the time. For example, if 95% of the data belongs to one class, a model that predicts the majority class for every instance would have 95% accuracy but would be ineffective for the minority class.  \n",
    "\n",
    "3. Inadequate Predictions: The model might not learn to distinguish between the classes effectively, leading to poor recall or precision for the minority class. This can be particularly problematic in applications like fraud detection, where missing out on fraudulent transactions (minority class) could be costly.  \n",
    "\n",
    "4. Overfitting to Majority Class: The model might overfit to the majority class due to its prevalence, failing to generalize well to the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0bbe9-aa72-44ea-9006-720b848d0bac",
   "metadata": {},
   "source": [
    "Q4. #### What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4cdbc-3429-4efe-ada3-0f733d9cf9e2",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "Up-sampling and Down-sampling are techniques used to address class imbalance in datasets, where one class (typically the minority class) has significantly fewer instances compared to the other class (majority class).  \n",
    "  \n",
    "**Up-sampling:**  \n",
    "Up-sampling involves increasing the number of instances in the minority class to match or exceed the number of instances in the majority class. This can be achieved by either duplicating existing instances or generating synthetic instances.  \n",
    "**When Up-sampling is Required:**  \n",
    "Example Scenario: In a credit card fraud detection system, fraud cases (minority class) are much less frequent compared to non-fraud cases (majority class). If the model is trained on this imbalanced dataset, it may perform poorly in identifying fraud cases because the model is biased towards the majority class.  \n",
    "\n",
    "**Down-sampling:**   \n",
    "Down-sampling involves reducing the number of instances in the majority class to match or approach the number of instances in the minority class. This technique helps in balancing the dataset but can lead to loss of information as some instances from the majority class are removed.  \n",
    "**When Down-sampling is Required:**  \n",
    "Example Scenario: In a fraud detection system where fraud cases are much fewer but the majority of non-fraud cases dominate the dataset, the model may become biased towards non-fraud cases. Down-sampling the majority class can help balance the dataset, making it easier for the model to learn about the minority class without being overwhelmed by the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa9895-47fb-47c7-a725-14965332bc90",
   "metadata": {},
   "source": [
    "#### 5. What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de0ffe-6ef2-4ec7-9576-41bde90fcf24",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "*Data Augmentation* refers to techniques used to increase the diversity and amount of data available for training machine learning models without actually collecting new data. It involves creating new training examples by transforming the existing data, which can help improve model performance, particularly in cases of limited data or imbalanced datasets.  \n",
    "\n",
    "**SMOTE (Synthetic Minority Over-sampling Technique):**  \n",
    "SMOTE is a widely used technique for addressing class imbalance in datasets, especially in classification problems. It works by generating synthetic instances for the minority class rather than simply duplicating existing instances. This helps the model to learn better and generalize more effectively.  \n",
    "  \n",
    "How SMOTE Works:  \n",
    "  \n",
    "1. Identify Neighbors: For each instance in the minority class, identify its k-nearest neighbors using a distance metric (e.g., Euclidean distance).  \n",
    "2. Generate Synthetic Samples: Create synthetic samples by interpolating between the minority class instance and its neighbors. Specifically, for each instance, new instances are generated along the line segments joining it to its neighbors.  \n",
    "Benefits of SMOTE:  \n",
    "1. Improves Class Distribution: By generating new examples, it balances the class distribution.  \n",
    "2. Reduces Overfitting: By creating new examples rather than duplicating existing ones, it helps to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953300c7-4dd9-48b5-b30b-ef150221474c",
   "metadata": {},
   "source": [
    "#### 6. What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48553cd5-d0a4-4f9e-bd68-ed6dc160a681",
   "metadata": {},
   "source": [
    "Ans:   \n",
    "*Outliers* are data points that differ significantly from other observations in a dataset. They can be unusually high or low compared to the majority of the data. Outliers can arise due to variability in the data, errors in data collection, or they might indicate significant phenomena or anomalies.  \n",
    "  \n",
    "Characteristics of Outliers:  \n",
    "1. Extreme Values: They lie far away from the central tendency (mean or median) of the data.  \n",
    "2. Influential Points: They can affect the statistical properties of the dataset, such as mean, variance, and correlation.  \n",
    "  \n",
    "Why is it Essential to Handle Outliers?  \n",
    "1. Impact on Statistical Measures:  \n",
    "Mean and Variance: Outliers can skew the mean and inflate the variance, leading to misleading statistical summaries.  \n",
    "Correlation: They can distort the relationships between variables, affecting correlation and regression analysis.  \n",
    "\n",
    "2. Model Performance:  \n",
    "Model Assumptions: Many statistical models assume that data is normally distributed. Outliers can violate these assumptions and lead to incorrect conclusions.  \n",
    "Predictive Accuracy: Outliers can negatively impact the performance of machine learning models, as they may lead to overfitting or underfitting. For example, in regression tasks, outliers can disproportionately affect the fit of the model.  \n",
    "\n",
    "3. Data Quality:  \n",
    "Errors and Noise: Outliers may indicate errors or inconsistencies in data collection or entry. Addressing these issues can improve the overall data quality.  \n",
    "Robustness: Handling outliers ensures that the analysis or model is robust and reliable.  \n",
    "\n",
    "4. Anomaly Detection:  \n",
    "Special Cases: In some contexts, outliers may represent important anomalies or events, such as fraud in financial transactions or rare diseases in medical data. Identifying these can be critical for specific applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5512d-218d-4ba1-99e9-0edb2e56eb64",
   "metadata": {},
   "source": [
    "Q7. You are working on a project that requires analyzing customer data. However, you notice that some of\r\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96d9f78-036a-43fc-ac26-51cc3d4281ae",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "Handling missing data is a crucial step in data preprocessing, as it can significantly affect the quality and outcomes of your analysis. There are several techniques you can use to address missing data, depending on the nature of the data and the extent of the missing values. Here are some common techniques:  \n",
    "  \n",
    "1. Remove Missing Data:\n",
    "Technique: Remove rows or columns that contain missing values.  \n",
    "Remove Rows: If only a small proportion of rows contain missing values, it might be acceptable to drop these rows.  \n",
    "Remove Columns: If a large proportion of a column is missing, or if a column has too many missing values, consider removing it.\n",
    "\n",
    "2. Fill(Impute) Missing Data:  \n",
    "Technique: Replace missing values with a specific value, such as the mean, median, mode, or a constant.    \n",
    "    1. Mean/Median/Mode Imputation: Useful for numerical data.  \n",
    "    2. Constant Imputation: Replacing missing values with a fixed value.\n",
    "  \n",
    "3. Forward Fill / Backward Fill:  \n",
    "Technique: Use the next or previous value in the column to fill missing data.  \n",
    "    1. Forward Fill (ffill): Fill missing values with the previous value in the column.  \n",
    "    2. Backward Fill (bfill): Fill missing values with the next value in the column.\n",
    "4. Predictive Modeling:  \n",
    "Technique: Use machine learning models to predict missing values based on other features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce597fc-ccad-438a-823f-d26b485e484b",
   "metadata": {},
   "source": [
    "Q8. You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944ef87-95fb-437b-a760-9e6076165d63",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "Visualization: One strategy is to visualize the data using plots and graphs to see if there are any patterns or trends in the missing data. For example, a heatmap can be used to show which values are missing in the dataset.  \n",
    "  \n",
    "Summary statistics: Another strategy is to calculate summary statistics for the missing data and compare them to the summary statistics for the non-missing data. If there are significant differences between the two, this may suggest that the missing data is not missing at random.  \n",
    "\n",
    "Imputation: Imputation can also be used to determine if the missing data is missing at random. If the imputed values are similar to the non-missing values, this may suggest that the missing data is missing at random. If the imputed values are significantly different, this may suggest that there is a pattern to the missing data.  \n",
    "  \n",
    "Statistical tests: Statistical tests can also be used to determine if the missing data is missing at random. For example, a chi-square test can be used to test whether the missing data is independent of other variables in the dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042bc088-75d6-4aa6-8f95-0d47ac095cb4",
   "metadata": {},
   "source": [
    "Q9. Suppose you are working on a medical diagnosis project and find that the majority of patients in the\r\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\r\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4438522-9353-4e3c-b2a5-1dcbbd18fba7",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "Evaluating machine learning models on imbalanced datasets, especially in scenarios like medical diagnosis where the condition of interest is rare, requires special attention to ensure that the model's performance is assessed accurately. Here are some strategies to evaluate performance effectively:\n",
    "But since these kind of datasets are usually  imbalanced in nature we can use some Resampling techniques such as oversampling the minority class or undersampling the majority class can also be used to balance the dataset. Once the dataset is balanced, standard metrics such as accuracy, precision, recall, F1-score, and ROC can be used to evaluate the performance of the model.  \n",
    "**Appropriate Metrics:**  \n",
    "Accuracy is not a reliable metric for imbalanced datasets, as a model can achieve high accuracy by simply predicting the majority class. Instead, focus on metrics that give a better picture of model performance across both classes:  \n",
    "  \n",
    "1. Precision: The proportion of true positive predictions out of all positive predictions made by the model. It is crucial for evaluating how well the model avoids false positives.  \n",
    "2. Recall (Sensitivity or True Positive Rate): The proportion of actual positive cases correctly identified by the model. It is crucial for evaluating how well the model captures the positive cases.  \n",
    "3. F1 Score: The harmonic mean of precision and recall. It balances precision and recall, especially useful when the class distribution is imbalanced.\n",
    "4. ROC-AUC (Receiver Operating Characteristic - Area Under Curve): Measures the model’s ability to distinguish between classes. AUC ranges from 0 to 1, where a higher value indicates better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80326d6-4082-4c07-b3e9-fe7fb983a1c1",
   "metadata": {},
   "source": [
    "Q10. When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b9a9d-c201-4cba-bd0b-625075ca2e09",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "When dealing with an unbalanced dataset where the majority of customers report being satisfied, it’s important to use methods to balance the dataset to improve the performance and fairness of your machine learning models. Down-sampling the majority class is one such method. Here’s a detailed look at techniques you can use to balance your dataset by down-sampling the majority class:  \n",
    "  \n",
    "1. Random undersampling: This method involves randomly selecting a subset of observations from the majority class to match the size of the minority class. This can be done using techniques such as RandomUnderSampler from the imblearn library in Python.  \r",
    "  \n",
    "2. \r\n",
    "Tomek links: This method involves identifying pairs of observations that are nearest neighbors and belong to different classes. The observation from the majority class is then removed to balance the dataset. This can be done using techniques such as TomekLinks from the imblearn library in Pytho\n",
    "  \n",
    "3. Synthetic minority oversampling technique (SMOTE): This method involves generating synthetic observations for the minority class to match the size of the majority class. SMOTE can be used in combination with random undersampling to balance the dataset. This can be done using techniques such as SMOTETomek from the imblearn library in Python.hon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dfa0dd-6e5e-4519-842f-194b9b1ba91d",
   "metadata": {},
   "source": [
    "Q11. You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\r\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\r\n",
    "balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca768ea-4581-4285-b54a-daac2591d94b",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "\n",
    "When dealing with an imbalanced dataset where the occurrence of a rare event (minority class) is very low, it's important to use techniques that can up-sample the minority class to create a more balanced dataset. This can help improve the performance and fairness of your machine learning models. Here are some methods and techniques you can use to up-sample the minority class:\n",
    "\n",
    "1. Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "Technique: SMOTE generates synthetic samples for the minority class by interpolating between existing minority class examples. This helps to create a larger and more diverse set of examples for the minority class.\n",
    "\n",
    "2. Adaptive Synthetic Sampling (ADASYN)\n",
    "Technique: ADASYN builds on SMOTE but focuses on generating more synthetic examples near the decision boundary. It creates more synthetic data where the minority class is difficult to classify.\n",
    "\n",
    "3. Borderline-SMOTE\n",
    "Technique: Borderline-SMOTE is a variant of SMOTE that only generates synthetic samples near the boundary between the majority and minority classes, focusing on areas where the model is likely to make errors.\n",
    "\n",
    "4. Random Over-Sampling\n",
    "Technique: Randomly duplicate existing examples from the minority class to increase its size. This method is simple but may lead to overfitting due to duplication.\n",
    "\n",
    "5. SMOTE-NC (SMOTE for Nominal and Continuous Features)\n",
    "Technique: SMOTE-NC is an extension of SMOTE that can handle both numerical and categorical features. It's useful if your dataset contains a mix of feature types.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ea2f9-3d45-4c7c-b9b3-f29c4699830d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
